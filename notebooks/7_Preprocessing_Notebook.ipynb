{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define all variables and set up data import / export\n",
    "\n",
    "### Data structure and setup:\n",
    "It may be necessary to do multiple runs of this pipeline in order to compare results. This notebook presumes that the data is structured in this manner:\n",
    "\n",
    "```drive/batch/run/images_corrected/barcoding/well-plate-site/results_files.csv```\n",
    "\n",
    "You will define the first three variables below. Note that if one of these folders is missing (for example, you don't have separate run folders), then you can define that variable as an empty string, e.g. `run=''`, and it will be excluded from the path.\n",
    "\n",
    "### Results output:\n",
    "You can define the name of the folder you would like to contain your results in the `jupyter_output` variable below. The results folder is currently set up to be saved in a `run` folder within the `batch` folder; you can change that behavior by adjusting the `output_path` variable. Running the cell below will automatically create an output folder if it doesn't exist. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set variables\n",
    "\n",
    "# top level directory for the pooled cell painting analysis\n",
    "drive = '/Users/pryder/GitHub/pearlryder_projects/2017_10_19_Profiling_rare_ORFs'\n",
    "\n",
    "# folder for batch specific data and results\n",
    "batch = '20210407_24W_CP251/'\n",
    "\n",
    "run = '7_BC_Preprocess_Results/run3-FociTh1point5'\n",
    "\n",
    "# folder w/ barcoding CSV result files\n",
    "csvfolder = os.path.join(drive, batch, run, 'images_corrected/', 'barcoding/')\n",
    "\n",
    "# define the name of a folder to save Jupyter notebook output\n",
    "jupyter_output = 'Jupyter-output'\n",
    "\n",
    "# create the output folder if it doesn't exist \n",
    "output_path = os.path.join(drive, batch, jupyter_output, run)\n",
    "\n",
    "if not os.path.isdir(output_path):\n",
    "    os.makedirs(output_path)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful function for merging CSVs contained in folders within one folder\n",
    "\n",
    "def merge_csvs(csvfolder, filename, column_list=None):\n",
    "    \"\"\" csvfolder is a path to a folder\n",
    "    Iterates over all of the folders inside of that CSVfolder\n",
    "    Merges the CSVs that match the filename into one dataframe \n",
    "    If a column list is passed, it keeps columns defined in the column list\n",
    "    Prints a time stamp every 500 csvs\n",
    "    Returns the merged dataframe\n",
    "    \"\"\"\n",
    "\n",
    "    df_dict={}\n",
    "    count = 0\n",
    "    folderlist = os.listdir(csvfolder)\n",
    "    print(count, datetime.datetime.ctime(datetime.datetime.now()))\n",
    "    for eachfolder in folderlist:\n",
    "            if os.path.isfile(os.path.join(csvfolder, eachfolder, filename)):\n",
    "                if not column_list:\n",
    "                    df_dict[eachfolder]=pandas.read_csv(os.path.join(csvfolder, eachfolder, filename),index_col=False)\n",
    "                else:\n",
    "                    df_dict[eachfolder]=pandas.read_csv(os.path.join(csvfolder, eachfolder, filename),index_col=False,usecols=column_list)\n",
    "                count+=1\n",
    "                if count % 500 == 0:\n",
    "                    print(count, datetime.datetime.ctime(datetime.datetime.now()))\n",
    "    print(count, datetime.datetime.ctime(datetime.datetime.now()))\n",
    "    df_merged = pandas.concat(df_dict, ignore_index=True)\n",
    "    print('done concatenating at', datetime.datetime.ctime(datetime.datetime.now()))\n",
    "    \n",
    "    return df_merged\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge CSVs\n",
    "\n",
    "The first step is to merge the various CSVs for our experiment.\n",
    "- The CSVs are stored in separate folders for each Well-Site and will be merged into one CSV in the next step.\n",
    "- The `_BarcodeFoci.csv` files contain the % perfect match to the barcode score within the `Intensity_..._Barcodes_Scores` columns. \n",
    "- The `_Foci.csv` files contain the text for the barcode called and the barcode matched along with a matching score\n",
    "- The Metadata columns are included in these CSVs \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read a single BarcodeFoci csv to determine the columns present in the data\n",
    "filename = 'BarcodePreprocessing_Foci.csv'\n",
    "\n",
    "sample_csv_df = pandas.read_csv(os.path.join(csvfolder, os.listdir(csvfolder)[0], filename))\n",
    "\n",
    "# print the column list; copy-edit this list if desired \n",
    "\n",
    "print(list(sample_csv_df.columns))\n",
    "# use this column list can be used to select the columns needed in the merged CSV, if desired  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge BarcodeFoci csvs\n",
    "#Run if csvs are in separate folders\n",
    "filename = 'BarcodePreprocessing_Foci.csv'\n",
    "column_list = ['ImageNumber', 'ObjectNumber', 'Metadata_Plate', 'Metadata_Site', 'Metadata_Well', 'Metadata_Well_Value', 'Barcode_BarcodeCalled', 'Barcode_MatchedTo_Barcode', 'Barcode_MatchedTo_GeneCode', 'Barcode_MatchedTo_ID', 'Barcode_MatchedTo_Score']\n",
    "\n",
    "df_foci = merge_csvs(csvfolder, filename, column_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the merged BarcodeFoci CSV\n",
    "output_filename = 'BarcodePreprocessing_Foci_Merged.csv'\n",
    "\n",
    "foci_path = os.path.join(output_path, output_filename)\n",
    "df_foci.to_csv(foci_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Merged CSVs\n",
    "\n",
    "If you've already merged and save your CSVs using the code above, you can skip to this step of the notebook. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# List the contents of the Jupyter notebook output path\n",
    "# See what CSVs have been saved and their names\n",
    "\n",
    "drivelist = os.listdir(output_path)\n",
    "filelist = [x for x in drivelist if not os.path.isdir(os.path.join(drive,x)) ]\n",
    "print(filelist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSVs into data frames\n",
    "\n",
    "df_foci = pandas.read_csv(os.path.join(output_path, 'BarcodePreprocessing_Foci_Merged.csv'))\n",
    "# df_cells=pandas.read_csv(os.path.join(drive, 'Cells_Merged.csv'))\n",
    "# df_image=pandas.read_csv(os.path.join(drive, 'Image_Merged.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Investigating barcode calling\n",
    "\n",
    "### Distribution of barcode matching scores for all wells:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# useful dataframe manipulations \n",
    "\n",
    "df_foci.sort_values(by=['Metadata_Well_Value', 'Metadata_Site'], inplace=True)\n",
    "\n",
    "df_foci['well-site'] = df_foci['Metadata_Well_Value'] + '-' + df_foci['Metadata_Site'].astype(str)\n",
    "\n",
    "df_foci_well_groups = df_foci.groupby(\"Metadata_Well_Value\")\n",
    "\n",
    "df_foci.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(df_foci['Barcode_MatchedTo_Score'], kde=False)\n",
    "\n",
    "\n",
    "distplot_filename = \"barcode-score-distribution.png\"\n",
    "distplot_path = os.path.join(output_path, distplot_filename)\n",
    "\n",
    "plt.savefig(distplot_path, dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution of barcode matching scores by well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns_displot = sns.displot(\n",
    "    df_foci, x=\"Barcode_MatchedTo_Score\", col=\"Metadata_Well_Value\", col_wrap=4\n",
    ")\n",
    "\n",
    "displot_filename = \"barcode-score-by-well.png\"\n",
    "displot_path = os.path.join(output_path, displot_filename)\n",
    "\n",
    "sns_displot.savefig(displot_path, dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Barcodes called\n",
    "The strings for the barcodes are saved in `Foci.csv` files for each well. Investigate: are the barcodes that are called most frequently all one letter? Are the bases (A, T, G, C) called an equal # of times? What percentage of barcodes are called at 100% accuracy? \n",
    "\n",
    "Since we have high variability between wells, we'll do this on a per well basis. That will help us to estimate if the barcodes are called inaccurately in different ways for each well. (For example, visual inspection of the Barcodes called for WellD4-Site41 suggests that \"A\" is being called at very high frequency).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which barcodes are being called most often?\n",
    "# Wells with barcodes like AAAAAAA called most often are probably low quality\n",
    "# print to this notebook and save in a text file\n",
    "\n",
    "barcode_filename = \"barcodes-by-well.txt\"\n",
    "barcode_filepath = os.path.join(output_path, barcode_filename)\n",
    "\n",
    "with open(barcode_filepath, \"w\") as barcode_file:\n",
    "\n",
    "    for well, df_foci_well in df_foci_well_groups:\n",
    "        print(well)\n",
    "        print(df_foci_well['Barcode_BarcodeCalled'].value_counts().head(10), '\\n')\n",
    "        \n",
    "        barcode_file.write(well + '\\n')\n",
    "        barcode_file.write(str(df_foci_well['Barcode_BarcodeCalled'].value_counts().head(10)) + '\\n\\n')\n",
    "\n",
    "barcode_file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is the % of each base?\n",
    "\n",
    "BarcodeCat = df_foci['Barcode_BarcodeCalled'].str.cat()\n",
    "\n",
    "countG = BarcodeCat.count('G')\n",
    "countT = BarcodeCat.count('T')\n",
    "countA = BarcodeCat.count('A')\n",
    "countC = BarcodeCat.count('C')\n",
    "\n",
    "print (\"Frequency of A is \" + str(float(countA)/float((len(BarcodeCat)))*100))\n",
    "print (\"Frequency of C is \" + str(float(countC)/float((len(BarcodeCat)))*100))\n",
    "print (\"Frequency of G is \" + str(float(countG)/float((len(BarcodeCat)))*100))\n",
    "print (\"Frequency of T is \" + str(float(countT)/float((len(BarcodeCat)))*100))\n",
    "\n",
    "# 39% GC in the probes themselves; A & T should be roughly 30% each \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's investigate % base distribution by well\n",
    "\n",
    "well_site_ls = []\n",
    "percent_close_ls = []\n",
    "percent_perfect_ls = []\n",
    "perfect_barcode_count_ls = []\n",
    "frequency_A_ls = []\n",
    "frequency_C_ls = []\n",
    "frequency_G_ls = []\n",
    "frequency_T_ls = []\n",
    "\n",
    "for well, df_foci_well in df_foci_well_groups:\n",
    "    BarcodeCat = df_foci_well['Barcode_BarcodeCalled'].str.cat()\n",
    "\n",
    "    countG = BarcodeCat.count('G')\n",
    "    countT = BarcodeCat.count('T')\n",
    "    countA = BarcodeCat.count('A')\n",
    "    countC = BarcodeCat.count('C')\n",
    "\n",
    "    well_site_ls.append(df_foci_well['Metadata_Well_Value'].iloc[0])    \n",
    "    percent_close_ls.append(sum(df_foci_well['Barcode_MatchedTo_Score']>=0.875)*100.0/sum(df_foci_well['Barcode_MatchedTo_Score']>0))\n",
    "    percent_perfect_ls.append(sum(df_foci_well['Barcode_MatchedTo_Score']==1)*100.0/sum(df_foci_well['Barcode_MatchedTo_Score']>0))    \n",
    "    perfect_barcode_count_ls.append(sum(df_foci_well['Barcode_MatchedTo_Score']==1))\n",
    "    \n",
    "    frequency_A_ls.append(float(countA)/float((len(BarcodeCat)))*100)\n",
    "    frequency_C_ls.append(float(countC)/float((len(BarcodeCat)))*100)\n",
    "    frequency_G_ls.append(float(countG)/float((len(BarcodeCat)))*100)\n",
    "    frequency_T_ls.append(float(countT)/float((len(BarcodeCat)))*100)\n",
    "        \n",
    "percent_perfect_df = pandas.DataFrame({'Metadata_Well_Value': well_site_ls, \n",
    "                                       'percent-perfect': percent_perfect_ls,\n",
    "                                       'percent-close': percent_close_ls, \n",
    "                                       'perfect-barcode-count': perfect_barcode_count_ls,\n",
    "                                       'frequency-A': frequency_A_ls,\n",
    "                                       'frequency-C': frequency_C_ls,\n",
    "                                       'frequency-G': frequency_G_ls,\n",
    "                                       'frequency-T': frequency_T_ls,\n",
    "                                      })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the % perfect dataframe to disk\n",
    "percent_perfect_df_filename = 'percent-perfect.csv'\n",
    "\n",
    "percent_perfect_path = os.path.join(output_path, percent_perfect_df_filename)\n",
    "\n",
    "percent_perfect_df.to_csv(percent_perfect_path)\n",
    "\n",
    "# % perfect, % close, and perfect barcode count data\n",
    "percent_perfect_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
